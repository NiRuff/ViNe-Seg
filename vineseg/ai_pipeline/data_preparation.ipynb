{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c586aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818fb490",
   "metadata": {},
   "source": [
    "Please keep this in mind when trying to train the model:\n",
    "\n",
    "- Create a folder for every dataset in data/ (e.g. data/example/)\n",
    "- Create a folder raw/, yolo/ and coco/ in your new folder (e.g. data/example/raw/)\n",
    "- Put your raw data in the raw/ folder\n",
    "- Generate the coco dicts for each dataset using the respective function (Following code)\n",
    "- Take a look at the example data.yaml file and create a fitting one for your dataset\n",
    "- Generate the yolo-specific .txt files using the function below\n",
    "    - If there are any errors related to a directory not existing, please make sure to create the structure like in the provided example\n",
    "- You are now ready to train the model using the data.yaml files\n",
    "- If you want to combine multiple datasets for the training process:\n",
    "    - Create a new 'dataset' folder like above\n",
    "    - Create a yolo folder and a fitting data.yaml files and split your data to train/test/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aad9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data/example  \n",
    "#├── coco  \n",
    "#│   └── coco_dict.json  \n",
    "#├── raw  \n",
    "#└── yolo  \n",
    "#    ├── data.yaml  \n",
    "#    ├── test  \n",
    "#    │   ├── images  \n",
    "#    │   │   └── neurofinder-00-00_png.rf.d901011138af37195cc5de5ec8e96035.jpg  \n",
    "#    │   └── labels  \n",
    "#    │       └── neurofinder-00-00_png.rf.d901011138af37195cc5de5ec8e96035.txt  \n",
    "#    ├── train  \n",
    "#    │   ├── images  \n",
    "#    │   │   └── neurofinder-00-00_png.rf.d901011138af37195cc5de5ec8e96035.jpg  \n",
    "#    │   └── labels  \n",
    "#    │       └── neurofinder-00-00_png.rf.d901011138af37195cc5de5ec8e96035.txt  \n",
    "#    └── val  \n",
    "#        ├── images  \n",
    "#        │   └── neurofinder-00-00_png.rf.d901011138af37195cc5de5ec8e96035.jpg  \n",
    "#        └── labels  \n",
    "#            └── neurofinder-00-00_png.rf.d901011138af37195cc5de5ec8e96035.txt  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef53450",
   "metadata": {},
   "source": [
    "# Generate coco_dicts for datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056eb847",
   "metadata": {},
   "source": [
    "## Neurofinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f420902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.neurofinder import \\\n",
    "    scale_pixel_values, \\\n",
    "    tiff_to_png, \\\n",
    "    generate_coco_dict\n",
    "\n",
    "\n",
    "input_path = \"data/train/neurofinder/raw\"\n",
    "output_path = \"data/train/neurofinder/coco\"\n",
    "\n",
    "# generate .png images from .tiff input data\n",
    "tiff_to_png(input_path, output_path)\n",
    "\n",
    "# get shape of .png images without channel\n",
    "img_shape = cv2.imread(os.path.join(output_path, os.listdir(output_path)[0])).shape[:2]\n",
    "\n",
    "# generate coco dict\n",
    "generate_coco_dict(input_path, output_path, img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0401382f",
   "metadata": {},
   "source": [
    "## Allen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea57345e",
   "metadata": {},
   "source": [
    "## OGB-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e9907a",
   "metadata": {},
   "source": [
    "## Naomi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc6eb1a",
   "metadata": {},
   "source": [
    "# Generate segmentation files for yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c15cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets.utils import coco_seg_to_yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17396931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with the generation of allen-dataset annotation files...\n",
      "Finished with allen!\n",
      "Starting with the generation of ogb1_up-dataset annotation files...\n",
      "Finished with ogb1_up!\n",
      "Starting with the generation of neurofinder-dataset annotation files...\n",
      "Finished with neurofinder!\n",
      "Starting with the generation of naomi-dataset annotation files...\n",
      "Finished with naomi!\n"
     ]
    }
   ],
   "source": [
    "# train / test / val\n",
    "splits = [.8, .1, .1]\n",
    "\n",
    "datasets = [\n",
    "    'allen',\n",
    "    'ogb1_up',\n",
    "    'neurofinder',\n",
    "    'naomi',\n",
    "]\n",
    "\n",
    "# generate yolo files\n",
    "for dataset in datasets:\n",
    "    print(f'Starting with the generation of {dataset}-dataset annotation files...')\n",
    "    coco_seg_to_yolov8(f'data/{dataset}/coco', f'data/{dataset}/yolo', splits)\n",
    "    print(f'Finished with {dataset}!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
